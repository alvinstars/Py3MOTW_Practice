{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sqlite3 - Embedded Relational Database\n",
    "\n",
    "Purpose:\tImplements an embedded relational database with SQL support.\n",
    "\n",
    "The sqlite3 module implements a Python DB-API 2.0 compliant interface to SQLite, an in-process relational database. SQLite is designed to be embedded in applications, instead of using a separate database server program such as MySQL, PostgreSQL, or Oracle. It is fast, rigorously tested, and flexible, making it suitable for prototyping and production deployment for some applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Database\n",
    "\n",
    "An SQLite database is stored as a single file on the file system. The library manages access to the file, including locking it to prevent corruption when multiple writers use it. The database is created the first time the file is accessed, but the application is responsible for managing the table definitions, or schema, within the database.\n",
    "\n",
    "This example looks for the database file before opening it with connect() so it knows when to create the schema for new databases.\n",
    "\n",
    "Running the script twice shows that it creates the empty file if it does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database exists, assume schema does, too.\n"
     ]
    }
   ],
   "source": [
    "# sqlite3_createdb.py\n",
    "import os\n",
    "import sqlite3\n",
    "\n",
    "db_filename = 'todo.db'\n",
    "\n",
    "db_is_new = not os.path.exists(db_filename)\n",
    "\n",
    "conn = sqlite3.connect(db_filename)\n",
    "\n",
    "if db_is_new:\n",
    "    print('Need to create schema')\n",
    "else:\n",
    "    print('Database exists, assume schema does, too.')\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the new database file, the next step is to create the schema to define the tables within the database. The remaining examples in this section all use the same database schema with tables for managing tasks. The details of the database schema are presented in the table below and the table below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project Table\n",
    "\n",
    "| Column      | Type | Description                     |\n",
    "|-------------|------|---------------------------------|\n",
    "| name        | text | Project name                    |\n",
    "| description | text | Long project description        |\n",
    "| deadline    | date | Due date for the entire project |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task Table\n",
    "\n",
    "| Column       | Type    | Description                                                   |\n",
    "|--------------|---------|---------------------------------------------------------------|\n",
    "| id           | number  | Unique task identifier                                        |\n",
    "| priority     | integer | Numerical priority, lower is more important                   |\n",
    "| details      | text    | Full task details                                             |\n",
    "| status       | text    | Task status (one of ‘new’, ‘pending’, ‘done’, or ‘canceled’). |\n",
    "| deadline     | date    | Due date for this task                                        |\n",
    "| completed_on | date    | When the task was completed.                                  |\n",
    "| project      | text    | The name of the project for this task.                        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data definition language (DDL) statements to create the tables are:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-- todo_schema.sql\n",
    "-- Schema for to-do application examples.\n",
    "\n",
    "-- Projects are high-level activities made up of tasks\n",
    "create table project (\n",
    "    name        text primary key,\n",
    "    description text,\n",
    "    deadline    date\n",
    ");\n",
    "\n",
    "-- Tasks are steps that can be taken to complete a project\n",
    "create table task (\n",
    "    id           integer primary key autoincrement not null,\n",
    "    priority     integer default 1,\n",
    "    details      text,\n",
    "    status       text,\n",
    "    deadline     date,\n",
    "    completed_on date,\n",
    "    project      text not null references project(name)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The executescript() method of the Connection can be used to run the DDL instructions to create the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! rm -f todo.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating schema\n",
      "Inserting initial data\n"
     ]
    }
   ],
   "source": [
    "# sqlite3_create_schema.py\n",
    "import os\n",
    "import sqlite3\n",
    "\n",
    "db_filename = 'todo.db'\n",
    "schema_filename = 'todo_schema.sql'\n",
    "\n",
    "db_is_new = not os.path.exists(db_filename)\n",
    "\n",
    "with sqlite3.connect(db_filename) as conn:\n",
    "    if db_is_new:\n",
    "        print('Creating schema')\n",
    "        with open(schema_filename, 'rt') as f:\n",
    "            schema = f.read()\n",
    "        conn.executescript(schema)\n",
    "\n",
    "        print('Inserting initial data')\n",
    "\n",
    "        conn.executescript(\"\"\"\n",
    "        insert into project (name, description, deadline)\n",
    "        values ('pymotw', 'Python Module of the Week',\n",
    "                '2016-11-01');\n",
    "\n",
    "        insert into task (details, status, deadline, project)\n",
    "        values ('write about select', 'done', '2016-04-25',\n",
    "                'pymotw');\n",
    "\n",
    "        insert into task (details, status, deadline, project)\n",
    "        values ('write about random', 'waiting', '2016-08-22',\n",
    "                'pymotw');\n",
    "\n",
    "        insert into task (details, status, deadline, project)\n",
    "        values ('write about sqlite3', 'active', '2017-07-31',\n",
    "                'pymotw');\n",
    "        \"\"\")\n",
    "    else:\n",
    "        print('Database exists, assume schema does, too.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the tables are created, a few insert statements create a sample project and related tasks. The sqlite3 command line program can be used to examine the contents of the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1|1|write about select|done|2016-04-25||pymotw\r\n",
      "2|1|write about random|waiting|2016-08-22||pymotw\r\n",
      "3|1|write about sqlite3|active|2017-07-31||pymotw\r\n"
     ]
    }
   ],
   "source": [
    "! sqlite3 todo.db 'select * from task'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Data\n",
    "\n",
    "To retrieve the values saved in the task table from within a Python program, create a Cursor from a database connection. A cursor produces a consistent view of the data, and is the primary means of interacting with a transactional database system like SQLite.\n",
    "\n",
    "Querying is a two step process. First, run the query with the cursor’s execute() method to tell the database engine what data to collect. Then, use fetchall() to retrieve the results. The return value is a sequence of tuples containing the values for the columns included in the select clause of the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 [1] write about select        [done    ] (2016-04-25)\n",
      " 2 [1] write about random        [waiting ] (2016-08-22)\n",
      " 3 [1] write about sqlite3       [active  ] (2017-07-31)\n"
     ]
    }
   ],
   "source": [
    "# sqlite3_select_tasks.py\n",
    "import sqlite3\n",
    "\n",
    "db_filename = 'todo.db'\n",
    "\n",
    "with sqlite3.connect(db_filename) as conn:\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "    select id, priority, details, status, deadline from task\n",
    "    where project = 'pymotw'\n",
    "    \"\"\")\n",
    "\n",
    "    for row in cursor.fetchall():\n",
    "        task_id, priority, details, status, deadline = row\n",
    "        print('{:2d} [{:d}] {:<25} [{:<8}] ({})'.format(\n",
    "            task_id, priority, details, status, deadline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results can be retrieved one at a time with fetchone(), or in fixed-size batches with fetchmany().\n",
    "\n",
    "The value passed to fetchmany() is the maximum number of items to return. If fewer items are available, the sequence returned will be smaller than the maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project details for Python Module of the Week (pymotw)\n",
      "  due 2016-11-01\n",
      "\n",
      "Next 5 tasks:\n",
      " 1 [1] write about select        [done    ] (2016-04-25)\n",
      " 2 [1] write about random        [waiting ] (2016-08-22)\n",
      " 3 [1] write about sqlite3       [active  ] (2017-07-31)\n"
     ]
    }
   ],
   "source": [
    "# sqlite3_select_variations.py\n",
    "import sqlite3\n",
    "\n",
    "db_filename = 'todo.db'\n",
    "\n",
    "with sqlite3.connect(db_filename) as conn:\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "    select name, description, deadline from project\n",
    "    where name = 'pymotw'\n",
    "    \"\"\")\n",
    "    name, description, deadline = cursor.fetchone()\n",
    "\n",
    "    print('Project details for {} ({})\\n  due {}'.format(\n",
    "        description, name, deadline))\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "    select id, priority, details, status, deadline from task\n",
    "    where project = 'pymotw' order by deadline\n",
    "    \"\"\")\n",
    "\n",
    "    print('\\nNext 5 tasks:')\n",
    "    for row in cursor.fetchmany(5):\n",
    "        task_id, priority, details, status, deadline = row\n",
    "        print('{:2d} [{:d}] {:<25} [{:<8}] ({})'.format(\n",
    "            task_id, priority, details, status, deadline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Metadata\n",
    "\n",
    "The DB-API 2.0 specification says that after execute() has been called, the Cursor should set its description attribute to hold information about the data that will be returned by the fetch methods. The API specification say that the description value is a sequence of tuples containing the column name, type, display size, internal size, precision, scale, and a flag that says whether null values are accepted.\n",
    "\n",
    "Because sqlite3 does not enforce type or size constraints on data inserted into a database, only the column name value is filled in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task table has these columns:\n",
      "('id', None, None, None, None, None, None)\n",
      "('priority', None, None, None, None, None, None)\n",
      "('details', None, None, None, None, None, None)\n",
      "('status', None, None, None, None, None, None)\n",
      "('deadline', None, None, None, None, None, None)\n",
      "('completed_on', None, None, None, None, None, None)\n",
      "('project', None, None, None, None, None, None)\n"
     ]
    }
   ],
   "source": [
    "# sqlite3_cursor_description.py\n",
    "import sqlite3\n",
    "\n",
    "db_filename = 'todo.db'\n",
    "\n",
    "with sqlite3.connect(db_filename) as conn:\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "    select * from task where project = 'pymotw'\n",
    "    \"\"\")\n",
    "\n",
    "    print('Task table has these columns:')\n",
    "    for colinfo in cursor.description:\n",
    "        print(colinfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row Objects\n",
    "\n",
    "By default, the values returned by the fetch methods as “rows” from the database are tuples. The caller is responsible for knowing the order of the columns in the query and extracting individual values from the tuple. When the number of values in a query grows, or the code working with the data is spread out in a library, it is usually easier to work with an object and access values using their column names. That way, the number and order of the tuple contents can change over time as the query is edited, and code depending on the query results is less likely to break.\n",
    "\n",
    "Connection objects have a row_factory property that allows the calling code to control the type of object created to represent each row in the query result set. sqlite3 also includes a Row class intended to be used as a row factory. Column values can be accessed through Row instances by using the column index or name.\n",
    "\n",
    "This version of the sqlite3_select_variations.py example has been re-written using Row instances instead of tuples. The row from the project table is still printed by accessing the column values through position, but the print statement for tasks uses keyword lookup instead, so it does not matter that the order of the columns in the query has been changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project details for Python Module of the Week (pymotw)\n",
      "  due 2016-11-01\n",
      "\n",
      "Next 5 tasks:\n",
      " 1 [1] write about select        [done    ] (2016-04-25)\n",
      " 2 [1] write about random        [waiting ] (2016-08-22)\n",
      " 3 [1] write about sqlite3       [active  ] (2017-07-31)\n"
     ]
    }
   ],
   "source": [
    "# sqlite3_row_factory.py\n",
    "import sqlite3\n",
    "\n",
    "db_filename = 'todo.db'\n",
    "\n",
    "with sqlite3.connect(db_filename) as conn:\n",
    "    # Change the row factory to use Row\n",
    "    conn.row_factory = sqlite3.Row\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "    select name, description, deadline from project\n",
    "    where name = 'pymotw'\n",
    "    \"\"\")\n",
    "    name, description, deadline = cursor.fetchone()\n",
    "\n",
    "    print('Project details for {} ({})\\n  due {}'.format(\n",
    "        description, name, deadline))\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "    select id, priority, status, deadline, details from task\n",
    "    where project = 'pymotw' order by deadline\n",
    "    \"\"\")\n",
    "\n",
    "    print('\\nNext 5 tasks:')\n",
    "    for row in cursor.fetchmany(5):\n",
    "        print('{:2d} [{:d}] {:<25} [{:<8}] ({})'.format(\n",
    "            row['id'], row['priority'], row['details'],\n",
    "            row['status'], row['deadline'],\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Variables with Queries\n",
    "\n",
    "Using queries defined as literal strings embedded in a program is inflexible. For example, when another project is added to the database the query to show the top five tasks should be updated to work with either project. One way to add more flexibility is to build an SQL statement with the desired query by combining values in Python. However, building a query string in this way is dangerous, and should be avoided. Failing to correctly escape special characters in the variable parts of the query can result in SQL parsing errors, or worse, a class of security vulnerabilities known as SQL-injection attacks, which allow intruders to execute arbitrary SQL statements in the database.\n",
    "\n",
    "The proper way to use dynamic values with queries is through host variables passed to execute() along with the SQL instruction. A placeholder value in the SQL is replaced with the value of the host variable when the statement is executed. Using host variables instead of inserting arbitrary values into the SQL before it is parsed avoids injection attacks because there is no chance that the untrusted values will affect how the SQL is parsed. SQLite supports two forms for queries with placeholders, positional and named."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional Parameters\n",
    "\n",
    "A question mark (?) denotes a positional argument, passed to execute() as a member of a tuple.\n",
    "\n",
    "The command line argument is passed safely to the query as a positional argument, and there is no chance for bad data to corrupt the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sqlite3_argument_positional.py\n",
    "import sqlite3\n",
    "import sys\n",
    "\n",
    "db_filename = 'todo.db'\n",
    "project_name = sys.argv[1]\n",
    "\n",
    "with sqlite3.connect(db_filename) as conn:\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    query = \"\"\"\n",
    "    select id, priority, details, status, deadline from task\n",
    "    where project = ?\n",
    "    \"\"\"\n",
    "\n",
    "    cursor.execute(query, (project_name,))\n",
    "\n",
    "    for row in cursor.fetchall():\n",
    "        task_id, priority, details, status, deadline = row\n",
    "        print('{:2d} [{:d}] {:<25} [{:<8}] ({})'.format(\n",
    "            task_id, priority, details, status, deadline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 [1] write about select        [done    ] (2016-04-25)\r\n",
      " 2 [1] write about random        [waiting ] (2016-08-22)\r\n",
      " 3 [1] write about sqlite3       [active  ] (2017-07-31)\r\n"
     ]
    }
   ],
   "source": [
    "! python3 sqlite3_argument_positional.py pymotw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Parameters\n",
    "\n",
    "Use named parameters for more complex queries with a lot of parameters, or where some parameters are repeated multiple times within the query. Named parameters are prefixed with a colon (e.g., :param_name).\n",
    "\n",
    "Neither positional nor named parameters need to be quoted or escaped, since they are given special treatment by the query parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sqlite3_argument_named.py\n",
    "import sqlite3\n",
    "import sys\n",
    "\n",
    "db_filename = 'todo.db'\n",
    "project_name = sys.argv[1]\n",
    "\n",
    "with sqlite3.connect(db_filename) as conn:\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    query = \"\"\"\n",
    "    select id, priority, details, status, deadline from task\n",
    "    where project = :project_name\n",
    "    order by deadline, priority\n",
    "    \"\"\"\n",
    "\n",
    "    cursor.execute(query, {'project_name': project_name})\n",
    "\n",
    "    for row in cursor.fetchall():\n",
    "        task_id, priority, details, status, deadline = row\n",
    "        print('{:2d} [{:d}] {:<25} [{:<8}] ({})'.format(\n",
    "            task_id, priority, details, status, deadline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 [1] write about select        [done    ] (2016-04-25)\r\n",
      " 2 [1] write about random        [waiting ] (2016-08-22)\r\n",
      " 3 [1] write about sqlite3       [active  ] (2017-07-31)\r\n"
     ]
    }
   ],
   "source": [
    "! python3 sqlite3_argument_named.py pymotw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query parameters can be used with select, insert, and update statements. They can appear in any part of the query where a literal value is legal.\n",
    "\n",
    "This update statement uses two named parameters. The id value is used to find the right row to modify, and the status value is written to the table."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# sqlite3_argument_update.py\n",
    "import sqlite3\n",
    "import sys\n",
    "\n",
    "db_filename = 'todo.db'\n",
    "id = int(sys.argv[1])\n",
    "status = sys.argv[2]\n",
    "\n",
    "with sqlite3.connect(db_filename) as conn:\n",
    "    cursor = conn.cursor()\n",
    "    query = \"update task set status = :status where id = :id\"\n",
    "    cursor.execute(query, {'status': status, 'id': id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! python3 sqlite3_argument_update.py 2 done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 [1] write about select        [done    ] (2016-04-25)\r\n",
      " 2 [1] write about random        [done    ] (2016-08-22)\r\n",
      " 3 [1] write about sqlite3       [active  ] (2017-07-31)\r\n"
     ]
    }
   ],
   "source": [
    "! python3 sqlite3_argument_named.py pymotw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulk Loading\n",
    "\n",
    "To apply the same SQL instruction to a large set of data, use executemany(). This is useful for loading data, since it avoids looping over the inputs in Python and lets the underlying library apply loop optimizations. This example program reads a list of tasks from a comma-separated value file using the csv module and loads them into the database."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# sqlite3_load_csv.py\n",
    "import csv\n",
    "import sqlite3\n",
    "import sys\n",
    "\n",
    "db_filename = 'todo.db'\n",
    "data_filename = sys.argv[1]\n",
    "\n",
    "SQL = \"\"\"\n",
    "insert into task (details, priority, status, deadline, project)\n",
    "values (:details, :priority, 'active', :deadline, :project)\n",
    "\"\"\"\n",
    "\n",
    "with open(data_filename, 'rt') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "\n",
    "    with sqlite3.connect(db_filename) as conn:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.executemany(SQL, csv_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline,project,priority,details\r\n",
      "2016-11-30,pymotw,2,\"finish reviewing markup\"\r\n",
      "2016-08-20,pymotw,2,\"revise chapter intros\"\r\n",
      "2016-11-01,pymotw,1,\"subtitle\"\r\n"
     ]
    }
   ],
   "source": [
    "! cat tasks.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! python3 sqlite3_load_csv.py tasks.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 [1] write about select        [done    ] (2016-04-25)\r\n",
      " 5 [2] revise chapter intros     [active  ] (2016-08-20)\r\n",
      " 2 [1] write about random        [done    ] (2016-08-22)\r\n",
      " 6 [1] subtitle                  [active  ] (2016-11-01)\r\n",
      " 4 [2] finish reviewing markup   [active  ] (2016-11-30)\r\n",
      " 3 [1] write about sqlite3       [active  ] (2017-07-31)\r\n"
     ]
    }
   ],
   "source": [
    "! python3 sqlite3_argument_named.py pymotw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Defining New Column Types\n",
    "\n",
    "SQLite has native support for integer, floating point, and text columns. Data of these types is converted automatically by sqlite3 from Python’s representation to a value that can be stored in the database, and back again, as needed. Integer values are loaded from the database into int or long variables, depending on the size of the value. Text is saved and retrieved as str, unless the text_factory for the Connection has been changed.\n",
    "\n",
    "Although SQLite only supports a few data types internally, sqlite3 includes facilities for defining custom types to allow a Python application to store any type of data in a column. Conversion for types beyond those supported by default is enabled in the database connection using the detect_types flag. Use PARSE_DECLTYPES if the column was declared using the desired type when the table was defined.\n",
    "\n",
    "sqlite3 provides converters for date and timestamp columns, using the classes date and datetime from the datetime module to represent the values in Python. Both date-related converters are enabled automatically when type-detection is turned on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without type detection:\n",
      "  id        1                          <class 'int'>\n",
      "  details   'write about select'       <class 'str'>\n",
      "  deadline  '2016-04-25'               <class 'str'>\n",
      "\n",
      "With type detection:\n",
      "  id        1                          <class 'int'>\n",
      "  details   'write about select'       <class 'str'>\n",
      "  deadline  datetime.date(2016, 4, 25) <class 'datetime.date'>\n"
     ]
    }
   ],
   "source": [
    "# sqlite3_date_types.py\n",
    "import sqlite3\n",
    "import sys\n",
    "\n",
    "db_filename = 'todo.db'\n",
    "\n",
    "sql = \"select id, details, deadline from task\"\n",
    "\n",
    "\n",
    "def show_deadline(conn):\n",
    "    conn.row_factory = sqlite3.Row\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql)\n",
    "    row = cursor.fetchone()\n",
    "    for col in ['id', 'details', 'deadline']:\n",
    "        print('  {:<8}  {!r:<26} {}'.format(\n",
    "            col, row[col], type(row[col])))\n",
    "    return\n",
    "\n",
    "print('Without type detection:')\n",
    "with sqlite3.connect(db_filename) as conn:\n",
    "    show_deadline(conn)\n",
    "\n",
    "print('\\nWith type detection:')\n",
    "with sqlite3.connect(db_filename,\n",
    "                     detect_types=sqlite3.PARSE_DECLTYPES,\n",
    "                     ) as conn:\n",
    "    show_deadline(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Two functions need to be registered to define a new type. The adapter takes the Python object as input and returns a byte string that can be stored in the database. The converter receives the string from the database and returns a Python object. Use register_adapter() to define an adapter function, and register_converter() for a converter function.\n",
    "\n",
    "This example uses pickle to save an object to a string that can be stored in the database, a useful technique for storing arbitrary objects, but one that does not allow querying based on object attributes. A real object-relational mapper, such as SQLAlchemy, that stores attribute values in their own columns will be more useful for large amounts of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm todo.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adapter_func(MyObj('this is a value to save'))\n",
      "\n",
      "adapter_func(MyObj(42))\n",
      "\n",
      "1\n",
      "converter_func(b'\\x80\\x03c__main__\\nMyObj\\nq\\x00)\\x81q\\x01}q\\x02X\\x03\\x00\\x00\\x00argq\\x03X\\x17\\x00\\x00\\x00this is a value to saveq\\x04sb.')\n",
      "\n",
      "2\n",
      "converter_func(b'\\x80\\x03c__main__\\nMyObj\\nq\\x00)\\x81q\\x01}q\\x02X\\x03\\x00\\x00\\x00argq\\x03K*sb.')\n",
      "\n",
      "Retrieved 1 MyObj('this is a value to save')\n",
      "  with type <class '__main__.MyObj'>\n",
      "\n",
      "Retrieved 2 MyObj(42)\n",
      "  with type <class '__main__.MyObj'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sqlite3_custom_type.py\n",
    "import pickle\n",
    "import sqlite3\n",
    "\n",
    "db_filename = 'todo.db'\n",
    "\n",
    "\n",
    "def adapter_func(obj):\n",
    "    \"\"\"Convert from in-memory to storage representation.\n",
    "    \"\"\"\n",
    "    print('adapter_func({})\\n'.format(obj))\n",
    "    return pickle.dumps(obj)\n",
    "\n",
    "\n",
    "def converter_func(data):\n",
    "    \"\"\"Convert from storage to in-memory representation.\n",
    "    \"\"\"\n",
    "    print('converter_func({!r})\\n'.format(data))\n",
    "    return pickle.loads(data)\n",
    "\n",
    "\n",
    "class MyObj:\n",
    "\n",
    "    def __init__(self, arg):\n",
    "        self.arg = arg\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'MyObj({!r})'.format(self.arg)\n",
    "\n",
    "# Register the functions for manipulating the type.\n",
    "sqlite3.register_adapter(MyObj, adapter_func)\n",
    "sqlite3.register_converter(\"MyObj\", converter_func)\n",
    "\n",
    "# Create some objects to save.  Use a list of tuples so\n",
    "# the sequence can be passed directly to executemany().\n",
    "to_save = [\n",
    "    (MyObj('this is a value to save'),),\n",
    "    (MyObj(42),),\n",
    "]\n",
    "\n",
    "with sqlite3.connect(\n",
    "        db_filename,\n",
    "        detect_types=sqlite3.PARSE_DECLTYPES) as conn:\n",
    "    # Create a table with column of type \"MyObj\"\n",
    "    conn.execute(\"\"\"\n",
    "    create table if not exists obj (\n",
    "        id    integer primary key autoincrement not null,\n",
    "        data  MyObj\n",
    "    )\n",
    "    \"\"\")\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Insert the objects into the database\n",
    "    cursor.executemany(\"insert into obj (data) values (?)\",\n",
    "                       to_save)\n",
    "\n",
    "    print(1)\n",
    "    # Query the database for the objects just saved\n",
    "    cursor.execute(\"select id, data from obj\")\n",
    "    print(2)\n",
    "    for obj_id, obj in cursor.fetchall():\n",
    "        print('Retrieved', obj_id, obj)\n",
    "        print('  with type', type(obj))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Determining Types for Columns\n",
    "\n",
    "There are two sources for types information about the data for a query. The original table declaration can be used to identify the type of a real column, as shown earlier. A type specifier can also be included in the select clause of the query itself using the form as \"name [type]\".\n",
    "\n",
    "Use the detect_types flag PARSE_COLNAMES when the type is part of the query instead of the original table definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! rm todo.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adapter_func(MyObj('this is a value to save'))\n",
      "\n",
      "adapter_func(MyObj(42))\n",
      "\n",
      "converter_func(b'\\x80\\x03c__main__\\nMyObj\\nq\\x00)\\x81q\\x01}q\\x02X\\x03\\x00\\x00\\x00argq\\x03X\\x17\\x00\\x00\\x00this is a value to saveq\\x04sb.')\n",
      "\n",
      "converter_func(b'\\x80\\x03c__main__\\nMyObj\\nq\\x00)\\x81q\\x01}q\\x02X\\x03\\x00\\x00\\x00argq\\x03K*sb.')\n",
      "\n",
      "Retrieved 1 MyObj('this is a value to save')\n",
      "  with type <class '__main__.MyObj'>\n",
      "\n",
      "Retrieved 2 MyObj(42)\n",
      "  with type <class '__main__.MyObj'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sqlite3_custom_type_column.py\n",
    "import pickle\n",
    "import sqlite3\n",
    "\n",
    "db_filename = 'todo.db'\n",
    "\n",
    "\n",
    "def adapter_func(obj):\n",
    "    \"\"\"Convert from in-memory to storage representation.\n",
    "    \"\"\"\n",
    "    print('adapter_func({})\\n'.format(obj))\n",
    "    return pickle.dumps(obj)\n",
    "\n",
    "\n",
    "def converter_func(data):\n",
    "    \"\"\"Convert from storage to in-memory representation.\n",
    "    \"\"\"\n",
    "    print('converter_func({!r})\\n'.format(data))\n",
    "    return pickle.loads(data)\n",
    "\n",
    "\n",
    "class MyObj:\n",
    "\n",
    "    def __init__(self, arg):\n",
    "        self.arg = arg\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'MyObj({!r})'.format(self.arg)\n",
    "\n",
    "# Register the functions for manipulating the type.\n",
    "sqlite3.register_adapter(MyObj, adapter_func)\n",
    "sqlite3.register_converter(\"MyObj\", converter_func)\n",
    "\n",
    "# Create some objects to save.  Use a list of tuples so we\n",
    "# can pass this sequence directly to executemany().\n",
    "to_save = [\n",
    "    (MyObj('this is a value to save'),),\n",
    "    (MyObj(42),),\n",
    "]\n",
    "\n",
    "with sqlite3.connect(\n",
    "        db_filename,\n",
    "        detect_types=sqlite3.PARSE_COLNAMES) as conn:\n",
    "    # Create a table with column of type \"text\"\n",
    "    conn.execute(\"\"\"\n",
    "    create table if not exists obj2 (\n",
    "        id    integer primary key autoincrement not null,\n",
    "        data  text\n",
    "    )\n",
    "    \"\"\")\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Insert the objects into the database\n",
    "    cursor.executemany(\"insert into obj2 (data) values (?)\",\n",
    "                       to_save)\n",
    "\n",
    "    # Query the database for the objects just saved,\n",
    "    # using a type specifier to convert the text\n",
    "    # to objects.\n",
    "    cursor.execute(\n",
    "        'select id, data as \"pickle [MyObj]\" from obj2',\n",
    "    )\n",
    "    for obj_id, obj in cursor.fetchall():\n",
    "        print('Retrieved', obj_id, obj)\n",
    "        print('  with type', type(obj))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Transactions\n",
    "\n",
    "One of the key features of relational databases is the use of transactions to maintain a consistent internal state. With transactions enabled, several changes can be made through one connection without effecting any other users until the results are committed and flushed to the actual database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Preserving Changes\n",
    "\n",
    "Changes to the database, either through insert or update statements, need to be saved by explicitly calling commit(). This requirement gives an application an opportunity to make several related changes together, so they are stored atomically instead of incrementally, and avoids a situation where partial updates are seen by different clients connecting to the database simultaneously.\n",
    "\n",
    "The effect of calling commit() can be seen with a program that uses several connections to the database. A new row is inserted with the first connection, and then two attempts are made to read it back using separate connections.\n",
    "\n",
    "When show_projects() is called before conn1 has been committed, the results depend on which connection is used. Since the change was made through conn1, it sees the altered data. However, conn2 does not. After committing, the new connection conn3 sees the inserted row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm todo.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating schema\n",
      "Inserting initial data\n"
     ]
    }
   ],
   "source": [
    "# sqlite3_create_schema.py\n",
    "import os\n",
    "import sqlite3\n",
    "\n",
    "db_filename = 'todo.db'\n",
    "schema_filename = 'todo_schema.sql'\n",
    "\n",
    "db_is_new = not os.path.exists(db_filename)\n",
    "\n",
    "with sqlite3.connect(db_filename) as conn:\n",
    "    if db_is_new:\n",
    "        print('Creating schema')\n",
    "        with open(schema_filename, 'rt') as f:\n",
    "            schema = f.read()\n",
    "        conn.executescript(schema)\n",
    "\n",
    "        print('Inserting initial data')\n",
    "\n",
    "        conn.executescript(\"\"\"\n",
    "        insert into project (name, description, deadline)\n",
    "        values ('pymotw', 'Python Module of the Week',\n",
    "                '2016-11-01');\n",
    "\n",
    "        insert into task (details, status, deadline, project)\n",
    "        values ('write about select', 'done', '2016-04-25',\n",
    "                'pymotw');\n",
    "\n",
    "        insert into task (details, status, deadline, project)\n",
    "        values ('write about random', 'waiting', '2016-08-22',\n",
    "                'pymotw');\n",
    "\n",
    "        insert into task (details, status, deadline, project)\n",
    "        values ('write about sqlite3', 'active', '2017-07-31',\n",
    "                'pymotw');\n",
    "        \"\"\")\n",
    "    else:\n",
    "        print('Database exists, assume schema does, too.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project table has these columns:\n",
      "('name', None, None, None, None, None, None)\n",
      "('description', None, None, None, None, None, None)\n",
      "('deadline', None, None, None, None, None, None)\n",
      "('pymotw', 'Python Module of the Week', '2016-11-01')\n"
     ]
    }
   ],
   "source": [
    "# sqlite3_cursor_description.py\n",
    "import sqlite3\n",
    "\n",
    "db_filename = 'todo.db'\n",
    "\n",
    "with sqlite3.connect(db_filename) as conn:\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "    select * from project\n",
    "    \"\"\")\n",
    "\n",
    "    print('Project table has these columns:')\n",
    "    for colinfo in cursor.description:\n",
    "        print(colinfo)\n",
    "    for a in cursor.fetchall():\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before changes:\n",
      "   pymotw\n",
      "\n",
      "After changes in conn1:\n",
      "   pymotw\n",
      "   virtualenvwrapper\n",
      "\n",
      "Before commit:\n",
      "   pymotw\n",
      "\n",
      "After commit:\n",
      "   pymotw\n",
      "   virtualenvwrapper\n"
     ]
    }
   ],
   "source": [
    "# sqlite3_transaction_commit.py\n",
    "import sqlite3\n",
    "\n",
    "db_filename = 'todo.db'\n",
    "\n",
    "\n",
    "def show_projects(conn):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('select name, description from project')\n",
    "    for name, desc in cursor.fetchall():\n",
    "        print('  ', name)\n",
    "\n",
    "\n",
    "with sqlite3.connect(db_filename) as conn1:\n",
    "    print('Before changes:')\n",
    "    show_projects(conn1)\n",
    "\n",
    "    # Insert in one cursor\n",
    "    cursor1 = conn1.cursor()\n",
    "    cursor1.execute(\"\"\"\n",
    "    insert into project (name, description, deadline)\n",
    "    values ('virtualenvwrapper', 'Virtualenv Extensions',\n",
    "            '2011-01-01')\n",
    "    \"\"\")\n",
    "\n",
    "    print('\\nAfter changes in conn1:')\n",
    "    show_projects(conn1)\n",
    "\n",
    "    # Select from another connection, without committing first\n",
    "    print('\\nBefore commit:')\n",
    "    with sqlite3.connect(db_filename) as conn2:\n",
    "        show_projects(conn2)\n",
    "\n",
    "    # Commit then select from another connection\n",
    "    conn1.commit()\n",
    "    print('\\nAfter commit:')\n",
    "    with sqlite3.connect(db_filename) as conn3:\n",
    "        show_projects(conn3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Discarding Changes\n",
    "\n",
    "Uncommitted changes can also be discarded entirely using rollback(). The commit() and rollback() methods are usually called from different parts of the same try:except block, with errors triggering a rollback.\n",
    "\n",
    "After calling rollback(), the changes to the database are no longer present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before changes:\n",
      "   pymotw\n",
      "   virtualenvwrapper\n",
      "\n",
      "After delete:\n",
      "   pymotw\n",
      "ERROR: simulated error\n",
      "\n",
      "After rollback:\n",
      "   pymotw\n",
      "   virtualenvwrapper\n"
     ]
    }
   ],
   "source": [
    "# sqlite3_transaction_rollback.py\n",
    "import sqlite3\n",
    "\n",
    "db_filename = 'todo.db'\n",
    "\n",
    "\n",
    "def show_projects(conn):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('select name, description from project')\n",
    "    for name, desc in cursor.fetchall():\n",
    "        print('  ', name)\n",
    "\n",
    "\n",
    "with sqlite3.connect(db_filename) as conn:\n",
    "\n",
    "    print('Before changes:')\n",
    "    show_projects(conn)\n",
    "\n",
    "    try:\n",
    "\n",
    "        # Insert\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"\"\"delete from project\n",
    "                       where name = 'virtualenvwrapper'\n",
    "                       \"\"\")\n",
    "\n",
    "        # Show the settings\n",
    "        print('\\nAfter delete:')\n",
    "        show_projects(conn)\n",
    "\n",
    "        # Pretend the processing caused an error\n",
    "        raise RuntimeError('simulated error')\n",
    "\n",
    "    except Exception as err:\n",
    "        # Discard the changes\n",
    "        print('ERROR:', err)\n",
    "        conn.rollback()\n",
    "\n",
    "    else:\n",
    "        # Save the changes\n",
    "        conn.commit()\n",
    "\n",
    "    # Show the results\n",
    "    print('\\nAfter rollback:')\n",
    "    show_projects(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Isolation Levels\n",
    "\n",
    "sqlite3 supports three locking modes, called isolation levels, that control the technique used to prevent incompatible changes between connections. The isolation level is set by passing a string as the isolation_level argument when a connection is opened, so different connections can use different values.\n",
    "\n",
    "This program demonstrates the effect of different isolation levels on the order of events in threads using separate connections to the same database. Four threads are created. Two threads write changes to the database by updating existing rows. The other two threads attempt to read all of the rows from the task table.\n",
    "\n",
    "The threads are synchronized using an Event object from the threading module. The writer() function connects and make changes to the database, but does not commit before the event fires. The reader() function connects, then waits to query the database until after the synchronization event occurs."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# sqlite3_isolation_levels.py\n",
    "import logging\n",
    "import sqlite3\n",
    "import sys\n",
    "import threading\n",
    "import time\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s (%(threadName)-10s) %(message)s',\n",
    ")\n",
    "\n",
    "db_filename = 'todo.db'\n",
    "isolation_level = sys.argv[1]\n",
    "\n",
    "\n",
    "def writer():\n",
    "    with sqlite3.connect(\n",
    "            db_filename,\n",
    "            isolation_level=isolation_level) as conn:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('update task set priority = priority + 1')\n",
    "        logging.debug('waiting to synchronize')\n",
    "        ready.wait()  # synchronize threads\n",
    "        logging.debug('PAUSING')\n",
    "        time.sleep(1)\n",
    "        conn.commit()\n",
    "        logging.debug('CHANGES COMMITTED')\n",
    "\n",
    "\n",
    "def reader():\n",
    "    with sqlite3.connect(\n",
    "            db_filename,\n",
    "            isolation_level=isolation_level) as conn:\n",
    "        cursor = conn.cursor()\n",
    "        logging.debug('waiting to synchronize')\n",
    "        ready.wait()  # synchronize threads\n",
    "        logging.debug('wait over')\n",
    "        cursor.execute('select * from task')\n",
    "        logging.debug('SELECT EXECUTED')\n",
    "        cursor.fetchall()\n",
    "        logging.debug('results fetched')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ready = threading.Event()\n",
    "\n",
    "    threads = [\n",
    "        threading.Thread(name='Reader 1', target=reader),\n",
    "        threading.Thread(name='Reader 2', target=reader),\n",
    "        threading.Thread(name='Writer 1', target=writer),\n",
    "        threading.Thread(name='Writer 2', target=writer),\n",
    "    ]\n",
    "\n",
    "    [t.start() for t in threads]\n",
    "\n",
    "    time.sleep(1)\n",
    "    logging.debug('setting ready')\n",
    "    ready.set()\n",
    "\n",
    "    [t.join() for t in threads]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Deferred\n",
    "\n",
    "The default isolation level is DEFERRED. Using deferred mode locks the database, but only once a change is begun. All of the previous examples use deferred mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-03-12 16:48:51,705 (Reader 1  ) waiting to synchronize\n",
      "2017-03-12 16:48:51,705 (Reader 2  ) waiting to synchronize\n",
      "2017-03-12 16:48:51,707 (Writer 1  ) waiting to synchronize\n",
      "2017-03-12 16:48:52,708 (MainThread) setting ready\n",
      "2017-03-12 16:48:52,709 (Reader 1  ) wait over\n",
      "2017-03-12 16:48:52,709 (Writer 1  ) PAUSING\n",
      "2017-03-12 16:48:52,709 (Reader 2  ) wait over\n",
      "2017-03-12 16:48:52,710 (Reader 1  ) SELECT EXECUTED\n",
      "2017-03-12 16:48:52,710 (Reader 1  ) results fetched\n",
      "2017-03-12 16:48:52,710 (Reader 2  ) SELECT EXECUTED\n",
      "2017-03-12 16:48:52,711 (Reader 2  ) results fetched\n",
      "2017-03-12 16:48:53,715 (Writer 1  ) CHANGES COMMITTED\n",
      "2017-03-12 16:48:53,805 (Writer 2  ) waiting to synchronize\n",
      "2017-03-12 16:48:53,805 (Writer 2  ) PAUSING\n",
      "2017-03-12 16:48:54,807 (Writer 2  ) CHANGES COMMITTED\n"
     ]
    }
   ],
   "source": [
    "! python3 sqlite3_isolation_levels.py DEFERRED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Immediate\n",
    "\n",
    "Immediate mode locks the database as soon as a change starts and prevents other cursors from making changes until the transaction is committed. It is suitable for a database with complicated writes, but more readers than writers, since the readers are not blocked while the transaction is ongoing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-03-12 16:48:55,030 (Reader 1  ) waiting to synchronize\n",
      "2017-03-12 16:48:55,031 (Reader 2  ) waiting to synchronize\n",
      "2017-03-12 16:48:55,033 (Writer 2  ) waiting to synchronize\n",
      "2017-03-12 16:48:56,030 (MainThread) setting ready\n",
      "2017-03-12 16:48:56,030 (Reader 1  ) wait over\n",
      "2017-03-12 16:48:56,030 (Reader 2  ) wait over\n",
      "2017-03-12 16:48:56,031 (Writer 2  ) PAUSING\n",
      "2017-03-12 16:48:56,031 (Reader 1  ) SELECT EXECUTED\n",
      "2017-03-12 16:48:56,031 (Reader 1  ) results fetched\n",
      "2017-03-12 16:48:56,031 (Reader 2  ) SELECT EXECUTED\n",
      "2017-03-12 16:48:56,032 (Reader 2  ) results fetched\n",
      "2017-03-12 16:48:57,034 (Writer 2  ) CHANGES COMMITTED\n",
      "2017-03-12 16:48:57,038 (Writer 1  ) waiting to synchronize\n",
      "2017-03-12 16:48:57,038 (Writer 1  ) PAUSING\n",
      "2017-03-12 16:48:58,045 (Writer 1  ) CHANGES COMMITTED\n"
     ]
    }
   ],
   "source": [
    "! python3 sqlite3_isolation_levels.py IMMEDIATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exclusive\n",
    "\n",
    "Exclusive mode locks the database to all readers and writers. Its use should be limited in situations where database performance is important, since each exclusive connection blocks all other users.\n",
    "\n",
    "Because the first writer has started making changes, the readers and second writer block until it commits. The sleep() call introduces an artificial delay in the writer thread to highlight the fact that the other connections are blocking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-03-12 16:48:58,291 (Reader 2  ) waiting to synchronize\n",
      "2017-03-12 16:48:58,292 (Reader 1  ) waiting to synchronize\n",
      "2017-03-12 16:48:58,295 (Writer 1  ) waiting to synchronize\n",
      "2017-03-12 16:48:59,291 (MainThread) setting ready\n",
      "2017-03-12 16:48:59,291 (Reader 2  ) wait over\n",
      "2017-03-12 16:48:59,291 (Writer 1  ) PAUSING\n",
      "2017-03-12 16:48:59,292 (Reader 1  ) wait over\n",
      "2017-03-12 16:49:00,298 (Writer 1  ) CHANGES COMMITTED\n",
      "2017-03-12 16:49:00,306 (Writer 2  ) waiting to synchronize\n",
      "2017-03-12 16:49:00,307 (Writer 2  ) PAUSING\n",
      "2017-03-12 16:49:01,314 (Writer 2  ) CHANGES COMMITTED\n",
      "2017-03-12 16:49:01,391 (Reader 1  ) SELECT EXECUTED\n",
      "2017-03-12 16:49:01,392 (Reader 1  ) results fetched\n",
      "2017-03-12 16:49:01,391 (Reader 2  ) SELECT EXECUTED\n",
      "2017-03-12 16:49:01,392 (Reader 2  ) results fetched\n"
     ]
    }
   ],
   "source": [
    "! python3 sqlite3_isolation_levels.py EXCLUSIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Autocommit\n",
    "\n",
    "The isolation_level parameter for the connection can also be set to None to enable autocommit mode. With autocommit enabled, each execute() call is committed immediately when the statement finishes. Autocommit mode is suited for short transactions, such as those that insert a small amount of data into a single table. The database is locked for as little time as possible, so there is less chance of contention between threads.\n",
    "\n",
    "In sqlite3_autocommit.py, the explicit call to commit() has been removed and the isolation level is set to None, but otherwise is the same as sqlite3_isolation_levels.py. The output is different, however, since both writer threads finish their work before either reader starts querying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-03-12 16:49:01,604 (Reader 1  ) waiting to synchronize\n",
      "2017-03-12 16:49:01,605 (Reader 2  ) waiting to synchronize\n",
      "2017-03-12 16:49:01,608 (Writer 2  ) waiting to synchronize\n",
      "2017-03-12 16:49:01,609 (Writer 1  ) waiting to synchronize\n",
      "2017-03-12 16:49:02,607 (MainThread) setting ready\n",
      "2017-03-12 16:49:02,607 (Writer 1  ) PAUSING\n",
      "2017-03-12 16:49:02,607 (Writer 2  ) PAUSING\n",
      "2017-03-12 16:49:02,608 (Reader 1  ) wait over\n",
      "2017-03-12 16:49:02,608 (Reader 2  ) wait over\n",
      "2017-03-12 16:49:02,610 (Reader 1  ) SELECT EXECUTED\n",
      "2017-03-12 16:49:02,610 (Reader 2  ) SELECT EXECUTED\n",
      "2017-03-12 16:49:02,610 (Reader 2  ) results fetched\n",
      "2017-03-12 16:49:02,610 (Reader 1  ) results fetched\n",
      "2017-03-12 16:49:03,608 (Writer 1  ) CHANGES COMMITTED\n",
      "2017-03-12 16:49:03,612 (Writer 2  ) CHANGES COMMITTED\n"
     ]
    }
   ],
   "source": [
    "!python3 sqlite3_autocommit.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## In-Memory Databases\n",
    "\n",
    "SQLite supports managing an entire database in RAM, instead of relying on a disk file. In-memory databases are useful for automated testing, where the database does not need to be preserved between test runs, or when experimenting with a schema or other database features. To open an in-memory database, use the string ':memory:' instead of a filename when creating the Connection. Each ':memory:' connection creates a separate database instance, so changes made by a cursor in one do not effect other connections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exporting the Contents of a Database\n",
    "\n",
    "The contents of an in-memory database can be saved using the iterdump() method of the Connection. The iterator returned by iterdump() produces a series of strings that together build SQL instructions to recreate the state of the database.\n",
    "\n",
    "iterdump() can also be used with databases saved to files, but it is most useful for preserving a database that would not otherwise be saved. This output has been edited to fit on the page while remaining syntactically correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating schema\n",
      "Inserting initial data\n",
      "Dumping:\n",
      "BEGIN TRANSACTION;\n",
      "CREATE TABLE project (\n",
      "    name        text primary key,\n",
      "    description text,\n",
      "    deadline    date\n",
      ");\n",
      "INSERT INTO \"project\" VALUES('pymotw','Python Module of the Week','2010-11-01');\n",
      "DELETE FROM \"sqlite_sequence\";\n",
      "INSERT INTO \"sqlite_sequence\" VALUES('task',3);\n",
      "CREATE TABLE task (\n",
      "    id           integer primary key autoincrement not null,\n",
      "    priority     integer default 1,\n",
      "    details      text,\n",
      "    status       text,\n",
      "    deadline     date,\n",
      "    completed_on date,\n",
      "    project      text not null references project(name)\n",
      ");\n",
      "INSERT INTO \"task\" VALUES(1,1,'write about select','done','2010-10-03',NULL,'pymotw');\n",
      "INSERT INTO \"task\" VALUES(2,1,'write about random','waiting','2010-10-10',NULL,'pymotw');\n",
      "INSERT INTO \"task\" VALUES(3,1,'write about sqlite3','active','2010-10-17',NULL,'pymotw');\n",
      "COMMIT;\n"
     ]
    }
   ],
   "source": [
    "# sqlite3_iterdump.py\n",
    "import sqlite3\n",
    "\n",
    "schema_filename = 'todo_schema.sql'\n",
    "\n",
    "with sqlite3.connect(':memory:') as conn:\n",
    "    conn.row_factory = sqlite3.Row\n",
    "\n",
    "    print('Creating schema')\n",
    "    with open(schema_filename, 'rt') as f:\n",
    "        schema = f.read()\n",
    "    conn.executescript(schema)\n",
    "\n",
    "    print('Inserting initial data')\n",
    "    conn.execute(\"\"\"\n",
    "    insert into project (name, description, deadline)\n",
    "    values ('pymotw', 'Python Module of the Week',\n",
    "            '2010-11-01')\n",
    "    \"\"\")\n",
    "    data = [\n",
    "        ('write about select', 'done', '2010-10-03',\n",
    "         'pymotw'),\n",
    "        ('write about random', 'waiting', '2010-10-10',\n",
    "         'pymotw'),\n",
    "        ('write about sqlite3', 'active', '2010-10-17',\n",
    "         'pymotw'),\n",
    "    ]\n",
    "    conn.executemany(\"\"\"\n",
    "    insert into task (details, status, deadline, project)\n",
    "    values (?, ?, ?, ?)\n",
    "    \"\"\", data)\n",
    "\n",
    "    print('Dumping:')\n",
    "    for text in conn.iterdump():\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Using Python Functions in SQL\n",
    "\n",
    "SQL syntax supports calling functions during queries, either in the column list or where clause of the select statement. This feature makes it possible to process data before returning it from the query, and can be used to convert between different formats, perform calculations that would be clumsy in pure SQL, and reuse application code.\n",
    "\n",
    "Functions are exposed using the create_function() method of the Connection. The parameters are the name of the function (as it should be used from within SQL), the number of arguments the function takes, and the Python function to expose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original values:\n",
      "(1, 'write about select')\n",
      "(2, 'write about random')\n",
      "(3, 'write about sqlite3')\n",
      "\n",
      "Encrypting...\n",
      "Encrypting 'write about select'\n",
      "Encrypting 'write about random'\n",
      "Encrypting 'write about sqlite3'\n",
      "\n",
      "Raw encrypted values:\n",
      "(1, 'jevgr nobhg fryrpg')\n",
      "(2, 'jevgr nobhg enaqbz')\n",
      "(3, 'jevgr nobhg fdyvgr3')\n",
      "\n",
      "Decrypting in query...\n",
      "Decrypting 'jevgr nobhg fryrpg'\n",
      "Decrypting 'jevgr nobhg enaqbz'\n",
      "Decrypting 'jevgr nobhg fdyvgr3'\n",
      "(1, 'write about select')\n",
      "(2, 'write about random')\n",
      "(3, 'write about sqlite3')\n",
      "\n",
      "Decrypting...\n",
      "Decrypting 'jevgr nobhg fryrpg'\n",
      "Decrypting 'jevgr nobhg enaqbz'\n",
      "Decrypting 'jevgr nobhg fdyvgr3'\n"
     ]
    }
   ],
   "source": [
    "# sqlite3_create_function.py\n",
    "import codecs\n",
    "import sqlite3\n",
    "\n",
    "db_filename = 'todo.db'\n",
    "\n",
    "\n",
    "def encrypt(s):\n",
    "    print('Encrypting {!r}'.format(s))\n",
    "    return codecs.encode(s, 'rot-13')\n",
    "\n",
    "\n",
    "def decrypt(s):\n",
    "    print('Decrypting {!r}'.format(s))\n",
    "    return codecs.encode(s, 'rot-13')\n",
    "\n",
    "\n",
    "with sqlite3.connect(db_filename) as conn:\n",
    "\n",
    "    conn.create_function('encrypt', 1, encrypt)\n",
    "    conn.create_function('decrypt', 1, decrypt)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Raw values\n",
    "    print('Original values:')\n",
    "    query = \"select id, details from task\"\n",
    "    cursor.execute(query)\n",
    "    for row in cursor.fetchall():\n",
    "        print(row)\n",
    "\n",
    "    print('\\nEncrypting...')\n",
    "    query = \"update task set details = encrypt(details)\"\n",
    "    cursor.execute(query)\n",
    "\n",
    "    print('\\nRaw encrypted values:')\n",
    "    query = \"select id, details from task\"\n",
    "    cursor.execute(query)\n",
    "    for row in cursor.fetchall():\n",
    "        print(row)\n",
    "\n",
    "    print('\\nDecrypting in query...')\n",
    "    query = \"select id, decrypt(details) from task\"\n",
    "    cursor.execute(query)\n",
    "    for row in cursor.fetchall():\n",
    "        print(row)\n",
    "\n",
    "    print('\\nDecrypting...')\n",
    "    query = \"update task set details = decrypt(details)\"\n",
    "    cursor.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Querying with Regular Expressions\n",
    "\n",
    "Sqlite supports several special user functions that are associated with SQL syntax. For example, a function regexp can be used in a query to check if a column’s string value matches a regular expression using the following syntax.\n",
    "\n",
    "SELECT * FROM table\n",
    "WHERE column REGEXP '.*pattern.*'\n",
    "\n",
    "This examples associates a function with regexp() to test values using Python’s re module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 [9] write about select        [done    ] (2016-04-25)\n",
      " 2 [9] write about random        [waiting ] (2016-08-22)\n",
      " 3 [9] write about sqlite3       [active  ] (2017-07-31)\n"
     ]
    }
   ],
   "source": [
    "# sqlite3_regex.py\n",
    "import re\n",
    "import sqlite3\n",
    "\n",
    "db_filename = 'todo.db'\n",
    "\n",
    "\n",
    "def regexp(pattern, input):\n",
    "    return bool(re.match(pattern, input))\n",
    "\n",
    "\n",
    "with sqlite3.connect(db_filename) as conn:\n",
    "    conn.row_factory = sqlite3.Row\n",
    "    conn.create_function('regexp', 2, regexp)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    pattern = '.*[wW]rite [aA]bout.*'\n",
    "\n",
    "    cursor.execute(\n",
    "        \"\"\"\n",
    "        select id, priority, details, status, deadline from task\n",
    "        where details regexp :pattern\n",
    "        order by deadline, priority\n",
    "        \"\"\",\n",
    "        {'pattern': pattern},\n",
    "    )\n",
    "\n",
    "    for row in cursor.fetchall():\n",
    "        task_id, priority, details, status, deadline = row\n",
    "        print('{:2d} [{:d}] {:<25} [{:<8}] ({})'.format(\n",
    "            task_id, priority, details, status, deadline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Custom Aggregation\n",
    "\n",
    "An aggregation function collects many pieces of individual data and summarizes it in some way. Examples of built-in aggregation functions are avg() (average), min(), max(), and count().\n",
    "\n",
    "The API for aggregators used by sqlite3 is defined in terms of a class with two methods. The step() method is called once for each data value as the query is processed. The finalize() method is called one time at the end of the query and should return the aggregate value. This example implements an aggregator for the arithmetic mode. It returns the value that appears most frequently in the input.\n",
    "\n",
    "The aggregator class is registered with the create_aggregate() method of the Connection. The parameters are the name of the function (as it should be used from within SQL), the number of arguments the step() method takes, and the class to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step('2016-04-25')\n",
      "step('2016-08-22')\n",
      "step('2017-07-31')\n",
      "finalize() -> '2016-04-25' (1 times)\n",
      "mode(deadline) is: 2016-04-25\n"
     ]
    }
   ],
   "source": [
    "# sqlite3_create_aggregate.py\n",
    "import sqlite3\n",
    "import collections\n",
    "\n",
    "db_filename = 'todo.db'\n",
    "\n",
    "\n",
    "class Mode:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.counter = collections.Counter()\n",
    "\n",
    "    def step(self, value):\n",
    "        print('step({!r})'.format(value))\n",
    "        self.counter[value] += 1\n",
    "\n",
    "    def finalize(self):\n",
    "        result, count = self.counter.most_common(1)[0]\n",
    "        print('finalize() -> {!r} ({} times)'.format(\n",
    "            result, count))\n",
    "        return result\n",
    "\n",
    "\n",
    "with sqlite3.connect(db_filename) as conn:\n",
    "    conn.create_aggregate('mode', 1, Mode)\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"\"\"\n",
    "    select mode(deadline) from task where project = 'pymotw'\n",
    "    \"\"\")\n",
    "    row = cursor.fetchone()\n",
    "    print('mode(deadline) is:', row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Threading and Connection Sharing\n",
    "\n",
    "For historical reasons having to do with old versions of SQLite, Connection objects cannot be shared between threads. Each thread must create its own connection to the database.\n",
    "\n",
    "Attempts to share a connection between threads result in an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting thread\n",
      "ERROR: SQLite objects created in a thread can only be used in that same thread.The object was created in thread id 140735838127040 and this is thread id 123145576243200\n"
     ]
    }
   ],
   "source": [
    "# sqlite3_threading.py\n",
    "import sqlite3\n",
    "import sys\n",
    "import threading\n",
    "import time\n",
    "\n",
    "db_filename = 'todo.db'\n",
    "isolation_level = None  # autocommit mode\n",
    "\n",
    "\n",
    "def reader(conn):\n",
    "    print('Starting thread')\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('select * from task')\n",
    "        cursor.fetchall()\n",
    "        print('results fetched')\n",
    "    except Exception as err:\n",
    "        print('ERROR:', err)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with sqlite3.connect(db_filename,\n",
    "                         isolation_level=isolation_level,\n",
    "                         ) as conn:\n",
    "        t = threading.Thread(name='Reader 1',\n",
    "                             target=reader,\n",
    "                             args=(conn,),\n",
    "                             )\n",
    "        t.start()\n",
    "        t.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Restricting Access to Data\n",
    "\n",
    "Although SQLite does not have user access controls found in other, larger, relational databases, it does have a mechanism for limiting access to columns. Each connection can install an authorizer function to grant or deny access to columns at runtime based on any desired criteria. The authorizer function is invoked during the parsing of SQL statements, and is passed five arguments. The first is an action code indicating the type of operation being performed (reading, writing, deleting, etc.). The rest of the arguments depend on the action code. For SQLITE_READ operations, the arguments are the name of the table, the name of the column, the location in the SQL where the access is occurring (main query, trigger, etc.), and None.\n",
    "\n",
    "This example uses SQLITE_IGNORE to cause the strings from the task.details column to be replaced with null values in the query results. It also prevents all access to the task.priority column by returning SQLITE_DENY, which in turn causes SQLite to raise an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SQLITE_IGNORE to mask a column value:\n",
      "\n",
      "authorizer_func(21, None, None, None, None)\n",
      "requesting permission to run a select statement\n",
      "\n",
      "authorizer_func(20, task, id, main, None)\n",
      "requesting access to column task.id from main\n",
      "\n",
      "authorizer_func(20, task, details, main, None)\n",
      "requesting access to column task.details from main\n",
      "  ignoring details column\n",
      "\n",
      "authorizer_func(20, task, project, main, None)\n",
      "requesting access to column task.project from main\n",
      "1 None\n",
      "2 None\n",
      "3 None\n",
      "\n",
      "Using SQLITE_DENY to deny access to a column:\n",
      "\n",
      "authorizer_func(21, None, None, None, None)\n",
      "requesting permission to run a select statement\n",
      "\n",
      "authorizer_func(20, task, id, main, None)\n",
      "requesting access to column task.id from main\n",
      "\n",
      "authorizer_func(20, task, priority, main, None)\n",
      "requesting access to column task.priority from main\n",
      "  preventing access to priority column\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:An unexpected error occurred while tokenizing input\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line string', (1, 4))\n",
      "\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": "access to task.priority is prohibited",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-fb663ac01dfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     cursor.execute(\"\"\"\n\u001b[1;32m     44\u001b[0m     \u001b[0mselect\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpriority\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtask\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mproject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'pymotw'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \"\"\")\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'details'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: access to task.priority is prohibited"
     ]
    }
   ],
   "source": [
    "# sqlite3_set_authorizer.py\n",
    "import sqlite3\n",
    "\n",
    "db_filename = 'todo.db'\n",
    "\n",
    "\n",
    "def authorizer_func(action, table, column, sql_location, ignore):\n",
    "    print('\\nauthorizer_func({}, {}, {}, {}, {})'.format(\n",
    "        action, table, column, sql_location, ignore))\n",
    "\n",
    "    response = sqlite3.SQLITE_OK  # be permissive by default\n",
    "\n",
    "    if action == sqlite3.SQLITE_SELECT:\n",
    "        print('requesting permission to run a select statement')\n",
    "        response = sqlite3.SQLITE_OK\n",
    "\n",
    "    elif action == sqlite3.SQLITE_READ:\n",
    "        print('requesting access to column {}.{} from {}'.format(\n",
    "            table, column, sql_location))\n",
    "        if column == 'details':\n",
    "            print('  ignoring details column')\n",
    "            response = sqlite3.SQLITE_IGNORE\n",
    "        elif column == 'priority':\n",
    "            print('  preventing access to priority column')\n",
    "            response = sqlite3.SQLITE_DENY\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "with sqlite3.connect(db_filename) as conn:\n",
    "    conn.row_factory = sqlite3.Row\n",
    "    conn.set_authorizer(authorizer_func)\n",
    "\n",
    "    print('Using SQLITE_IGNORE to mask a column value:')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"\"\"\n",
    "    select id, details from task where project = 'pymotw'\n",
    "    \"\"\")\n",
    "    for row in cursor.fetchall():\n",
    "        print(row['id'], row['details'])\n",
    "\n",
    "    print('\\nUsing SQLITE_DENY to deny access to a column:')\n",
    "    cursor.execute(\"\"\"\n",
    "    select id, priority from task where project = 'pymotw'\n",
    "    \"\"\")\n",
    "    for row in cursor.fetchall():\n",
    "        print(row['id'], row['details'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The possible action codes are available as constants in sqlite3, with names prefixed SQLITE_. Each type of SQL statement can be flagged, and access to individual columns can be controlled as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm todo.db"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
