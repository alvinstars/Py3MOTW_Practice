{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pickle - Object Serialization\n",
    "\n",
    "Purpose:\tObject serialization\n",
    "\n",
    "The pickle module implements an algorithm for turning an arbitrary Python object into a series of bytes. This process is also called serializing the object. The byte stream representing the object can then be transmitted or stored, and later reconstructed to create a new object with the same characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warning\n",
    "\n",
    "The documentation for pickle makes clear that it offers no security guarantees. In fact, unpickling data can execute arbitrary code. Be careful using pickle for inter-process communication or data storage, and do not trust data that cannot be verified as secure. See the hmac module for an example of a secure way to verify the source of a pickled data source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding and Decoding Data in Strings\n",
    "\n",
    "This first example Uses dumps() to encode a data structure as a string, then prints the string to the console. It uses a data structure made up of entirely built-in types. Instances of any class can be pickled, as will be illustrated in a later example.\n",
    "\n",
    "By default, the pickle will be written in a binary format most compatible when sharing between Python 3 programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: <class 'list'>\n",
      "[{'a': 'A', 'b': 2, 'c': 3.0}]\n",
      "\n",
      "<class 'bytes'>\n",
      "PICKLE: b'\\x80\\x03]q\\x00}q\\x01(X\\x01\\x00\\x00\\x00bq\\x02K\\x02X\\x01\\x00\\x00\\x00aq\\x03X\\x01\\x00\\x00\\x00Aq\\x04X\\x01\\x00\\x00\\x00cq\\x05G@\\x08\\x00\\x00\\x00\\x00\\x00\\x00ua.'\n"
     ]
    }
   ],
   "source": [
    "# pickle_string.py\n",
    "import pickle\n",
    "import pprint\n",
    "\n",
    "data = [{'a': 'A', 'b': 2, 'c': 3.0}]\n",
    "print('DATA:', end=' ')\n",
    "print(type(data))\n",
    "# print(data)\n",
    "pprint.pprint(data)\n",
    "\n",
    "print()\n",
    "\n",
    "data_string = pickle.dumps(data)\n",
    "print(type(data_string))\n",
    "print('PICKLE: {!r}'.format(data_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the data is serialized, it can be written to a file, socket, pipe, etc. Later, the file can be read and the data unpickled to construct a new object with the same values.\n",
    "\n",
    "The newly constructed object is equal to, but not the same object as, the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE:  [{'a': 'A', 'b': 2, 'c': 3.0}]\n",
      "AFTER :  [{'a': 'A', 'b': 2, 'c': 3.0}]\n",
      "SAME? : False\n",
      "EQUAL?: True\n"
     ]
    }
   ],
   "source": [
    "# pickle_unpickle.py\n",
    "import pickle\n",
    "import pprint\n",
    "\n",
    "data1 = [{'a': 'A', 'b': 2, 'c': 3.0}]\n",
    "print('BEFORE: ', end=' ')\n",
    "pprint.pprint(data1)\n",
    "\n",
    "data1_string = pickle.dumps(data1)\n",
    "\n",
    "data2 = pickle.loads(data1_string)\n",
    "print('AFTER : ', end=' ')\n",
    "pprint.pprint(data2)\n",
    "\n",
    "print('SAME? :', (data1 is data2))\n",
    "print('EQUAL?:', (data1 == data2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Streams\n",
    "\n",
    "In addition to dumps() and loads(), pickle provides convenience functions for working with file-like streams. It is possible to write multiple objects to a stream, and then read them from the stream without knowing in advance how many objects are written, or how big they are.\n",
    "\n",
    "The example simulates streams using two BytesIO buffers. The first receives the pickled objects, and its value is fed to a second from which load() reads. A simple database format could use pickles to store objects, too. The shelve module is one such implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRITING : pickle (elkcip)\n",
      "WRITING : preserve (evreserp)\n",
      "WRITING : last (tsal)\n",
      "READ    : pickle (elkcip)\n",
      "READ    : preserve (evreserp)\n",
      "READ    : last (tsal)\n"
     ]
    }
   ],
   "source": [
    "# pickle_stream.py\n",
    "import io\n",
    "import pickle\n",
    "import pprint\n",
    "\n",
    "\n",
    "class SimpleObject:\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.name_backwards = name[::-1]\n",
    "        return\n",
    "\n",
    "\n",
    "data = []\n",
    "data.append(SimpleObject('pickle'))\n",
    "data.append(SimpleObject('preserve'))\n",
    "data.append(SimpleObject('last'))\n",
    "\n",
    "# Simulate a file.\n",
    "out_s = io.BytesIO()\n",
    "\n",
    "# Write to the stream\n",
    "for o in data:\n",
    "    print('WRITING : {} ({})'.format(o.name, o.name_backwards))\n",
    "    pickle.dump(o, out_s)\n",
    "    out_s.flush()\n",
    "\n",
    "# Set up a read-able stream\n",
    "in_s = io.BytesIO(out_s.getvalue())\n",
    "\n",
    "# Read the data\n",
    "while True:\n",
    "    try:\n",
    "        o = pickle.load(in_s)\n",
    "    except EOFError:\n",
    "        break\n",
    "    else:\n",
    "        print('READ    : {} ({})'.format(\n",
    "            o.name, o.name_backwards))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides storing data, pickles are handy for inter-process communication. For example, os.fork() and os.pipe() can be used to establish worker processes that read job instructions from one pipe and write the results to another pipe. The core code for managing the worker pool and sending jobs in and receiving responses can be reused, since the job and response objects do not have to be based on a particular class. When using pipes or sockets, do not forget to flush after dumping each object, to push the data through the connection to the other end. See the multiprocessing module for a reusable worker pool manager."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems Reconstructing Objects\n",
    "\n",
    "When working with custom classes, the class being pickled must appear in the namespace of the process reading the pickle. Only the data for the instance is pickled, not the class definition. The class name is used to find the constructor to create the new object when unpickling. The following example writes instances of a class to a file.\n",
    "\n",
    "When run, the script creates a file based on the name given as argument on the command line."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# pickle_dump_to_file_1.py\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "\n",
    "class SimpleObject:\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        l = list(name)\n",
    "        l.reverse()\n",
    "        self.name_backwards = ''.join(l)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data = []\n",
    "    data.append(SimpleObject('pickle'))\n",
    "    data.append(SimpleObject('preserve'))\n",
    "    data.append(SimpleObject('last'))\n",
    "\n",
    "    filename = sys.argv[1]\n",
    "\n",
    "    with open(filename, 'wb') as out_s:\n",
    "        for o in data:\n",
    "            print('WRITING: {} ({})'.format(\n",
    "                o.name, o.name_backwards))\n",
    "            pickle.dump(o, out_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRITING: pickle (elkcip)\r\n",
      "WRITING: preserve (evreserp)\r\n",
      "WRITING: last (tsal)\r\n"
     ]
    }
   ],
   "source": [
    "!python3 pickle_dump_to_file_1.py test.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simplistic attempt to load the resulting pickled objects fails.\n",
    "\n",
    "This version fails because there is no SimpleObject class available."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# pickle_load_from_file_1.py\n",
    "import pickle\n",
    "import pprint\n",
    "import sys\n",
    "\n",
    "filename = sys.argv[1]\n",
    "\n",
    "with open(filename, 'rb') as in_s:\n",
    "    while True:\n",
    "        try:\n",
    "            o = pickle.load(in_s)\n",
    "        except EOFError:\n",
    "            break\n",
    "        else:\n",
    "            print('READ: {} ({})'.format(\n",
    "                o.name, o.name_backwards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"pickle_load_from_file_1.py\", line 11, in <module>\r\n",
      "    o = pickle.load(in_s)\r\n",
      "AttributeError: Can't get attribute 'SimpleObject' on <module '__main__' from 'pickle_load_from_file_1.py'>\r\n"
     ]
    }
   ],
   "source": [
    "! python3 pickle_load_from_file_1.py test.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corrected version, which imports SimpleObject from the original script, succeeds. Adding this import statement to the end of the import list allows the script to find the class and construct the object."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# pickle_load_from_file_2.py\n",
    "from pickle_dump_to_file_1 import SimpleObject\n",
    "import pickle\n",
    "import pprint\n",
    "import sys\n",
    "\n",
    "filename = sys.argv[1]\n",
    "\n",
    "with open(filename, 'rb') as in_s:\n",
    "    while True:\n",
    "        try:\n",
    "            o = pickle.load(in_s)\n",
    "        except EOFError:\n",
    "            break\n",
    "        else:\n",
    "            print('READ: {} ({})'.format(\n",
    "                o.name, o.name_backwards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READ: pickle (elkcip)\r\n",
      "READ: preserve (evreserp)\r\n",
      "READ: last (tsal)\r\n"
     ]
    }
   ],
   "source": [
    "!python3 pickle_load_from_file_2.py test.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpicklable Objects\n",
    "\n",
    "Not all objects can be pickled. Sockets, file handles, database connections, and other objects with runtime state that depends on the operating system or another process may not be able to be saved in a meaningful way. Objects that have non-picklable attributes can define \\__getstate\\__() and \\__setstate\\__() to return a subset of the state of the instance to be pickled.\n",
    "\n",
    "The \\__getstate\\__() method must return an object containing the internal state of the object. One convenient way to represent that state is with a dictionary, but the value can be any picklable object. The state is stored, and passed to \\__setstate\\__() when the object is loaded from the pickle.\n",
    "\n",
    "This example uses a separate State object to hold the internal state of MyClass. When an instance of MyClass is loaded from a pickle, __setstate__() is passed a State instance which it uses to initialize the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyClass.__init__(name here)\n",
      "Before: MyClass('name here') (computed='ereh eman')\n",
      "\n",
      "pickle.dumps...\n",
      "__getstate__ -> State({'name': 'name here'})\n",
      "\n",
      "pickle.loads...\n",
      "__setstate__(State({'name': 'name here'}))\n",
      "\n",
      "After: MyClass('name here') (computed='ereh eman')\n"
     ]
    }
   ],
   "source": [
    "# pickle_state.py\n",
    "import pickle\n",
    "\n",
    "\n",
    "class State:\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'State({!r})'.format(self.__dict__)\n",
    "\n",
    "\n",
    "class MyClass:\n",
    "\n",
    "    def __init__(self, name):\n",
    "        print('MyClass.__init__({})'.format(name))\n",
    "        self._set_name(name)\n",
    "\n",
    "    def _set_name(self, name):\n",
    "        self.name = name\n",
    "        self.computed = name[::-1]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'MyClass({!r}) (computed={!r})'.format(\n",
    "            self.name, self.computed)\n",
    "\n",
    "    def __getstate__(self):\n",
    "        state = State(self.name)\n",
    "        print('__getstate__ -> {!r}'.format(state))\n",
    "        return state\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        print('__setstate__({!r})'.format(state))\n",
    "        self._set_name(state.name)\n",
    "\n",
    "\n",
    "inst = MyClass('name here')\n",
    "print('Before:', inst)\n",
    "print('\\npickle.dumps...')\n",
    "dumped = pickle.dumps(inst)\n",
    "print('\\npickle.loads...')\n",
    "reloaded = pickle.loads(dumped)\n",
    "print('\\nAfter:', reloaded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warning\n",
    "If the return value is false, then __setstate__() is not called when the object is unpickled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circular References\n",
    "\n",
    "The pickle protocol automatically handles circular references between objects, so complex data structures do not need any special handling. Consider the directed graph in the figure. It includes several cycles, yet the correct structure can be pickled and then reloaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](graph/pickle_graph1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reloaded nodes are not the same object, but the relationship between the nodes is maintained and only one copy of the object with multiple references is reloaded. Both of these statements can be verified by examining the id() values for the nodes before and after being passed through pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL GRAPH:\n",
      " root (4368696656) ->  a (4368696992)\n",
      "    a (4368696992) ->  b (4368696208)\n",
      "    b (4368696208) ->  a (4368696992)\n",
      "    b (4368696208) ->  c (4368696376)\n",
      "    a (4368696992) ->  a (4368696992)\n",
      " root (4368696656) ->  b (4368696208)\n",
      "\n",
      "RELOADED GRAPH:\n",
      " root (4368696488) ->  a (4368451904)\n",
      "    a (4368451904) ->  b (4368453248)\n",
      "    b (4368453248) ->  a (4368451904)\n",
      "    b (4368453248) ->  c (4368685544)\n",
      "    a (4368451904) ->  a (4368451904)\n",
      " root (4368696488) ->  b (4368453248)\n"
     ]
    }
   ],
   "source": [
    "# pickle_cycle.py\n",
    "import pickle\n",
    "\n",
    "\n",
    "class Node:\n",
    "    \"\"\"A simple digraph\n",
    "    \"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.connections = []\n",
    "\n",
    "    def add_edge(self, node):\n",
    "        \"Create an edge between this node and the other.\"\n",
    "        self.connections.append(node)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.connections)\n",
    "\n",
    "\n",
    "def preorder_traversal(root, seen=None, parent=None):\n",
    "    \"\"\"Generator function to yield the edges in a graph.\n",
    "    \"\"\"\n",
    "\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "#     print('list(seen): ', list(x.name for x in seen))\n",
    "    yield (parent, root)\n",
    "#     print('yiled: parent - {}, root - {}'.format(id(parent), id(root)))\n",
    "    if root in seen:\n",
    "#         print('return')\n",
    "        return\n",
    "    seen.add(root)\n",
    "    for node in root:\n",
    "        recurse = preorder_traversal(node, seen, root)\n",
    "        for parent, subnode in recurse:\n",
    "            yield (parent, subnode)\n",
    "\n",
    "\n",
    "def show_edges(root):\n",
    "    \"Print all the edges in the graph.\"\n",
    "    for parent, child in preorder_traversal(root):       \n",
    "        if not parent:\n",
    "            continue\n",
    "        print('{:>5} ({}) -> {:>2} ({})'.format(\n",
    "            parent.name, id(parent), child.name, id(child)))\n",
    "\n",
    "\n",
    "# Set up the nodes.\n",
    "root = Node('root')\n",
    "a = Node('a')\n",
    "b = Node('b')\n",
    "c = Node('c')\n",
    "\n",
    "# Add edges between them.\n",
    "root.add_edge(a)\n",
    "root.add_edge(b)\n",
    "a.add_edge(b)\n",
    "b.add_edge(a)\n",
    "b.add_edge(c)\n",
    "a.add_edge(a)\n",
    "\n",
    "print('ORIGINAL GRAPH:')\n",
    "show_edges(root)\n",
    "\n",
    "# Pickle and unpickle the graph to create\n",
    "# a new set of nodes.\n",
    "dumped = pickle.dumps(root)\n",
    "reloaded = pickle.loads(dumped)\n",
    "\n",
    "print('\\nRELOADED GRAPH:')\n",
    "show_edges(reloaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL GRAPH:\n",
      "ENTERING preorder_traversal \"parent:<class 'NoneType'>(4296868152)\" \"child:root(4368732000)\" \n",
      "A: seen  []\n",
      "B: yield: <class 'NoneType'>(4296868152), root(4368732000) \n",
      "[SHOW_EDGE] parent - <class 'NoneType'>, continue\n",
      "D: seen after seen.add(child)  [('root', 4368732000)]\n",
      "E: Iter root(4368732000) and got subnode a(4368732056)\n",
      "ENTERING preorder_traversal \"parent:root(4368732000)\" \"child:a(4368732056)\" \n",
      "A: seen  [('root', 4368732000)]\n",
      "B: yield: root(4368732000), a(4368732056) \n",
      "F: yield: root(4368732000), a(4368732056) \n",
      "     ******[SHOW_EDGE]******  root (4368732000) ->  a (4368732056)\n",
      "D: seen after seen.add(child)  [('a', 4368732056), ('root', 4368732000)]\n",
      "E: Iter a(4368732056) and got subnode b(4368697048)\n",
      "ENTERING preorder_traversal \"parent:a(4368732056)\" \"child:b(4368697048)\" \n",
      "A: seen  [('a', 4368732056), ('root', 4368732000)]\n",
      "B: yield: a(4368732056), b(4368697048) \n",
      "F: yield: a(4368732056), b(4368697048) \n",
      "F: yield: a(4368732056), b(4368697048) \n",
      "     ******[SHOW_EDGE]******     a (4368732056) ->  b (4368697048)\n",
      "D: seen after seen.add(child)  [('a', 4368732056), ('b', 4368697048), ('root', 4368732000)]\n",
      "EXITING preorder_traversal !!!\n",
      "EXITING preorder_traversal !!!\n",
      "E: Iter root(4368732000) and got subnode b(4368697048)\n",
      "ENTERING preorder_traversal \"parent:root(4368732000)\" \"child:b(4368697048)\" \n",
      "A: seen  [('a', 4368732056), ('b', 4368697048), ('root', 4368732000)]\n",
      "B: yield: root(4368732000), b(4368697048) \n",
      "F: yield: root(4368732000), b(4368697048) \n",
      "     ******[SHOW_EDGE]******  root (4368732000) ->  b (4368697048)\n",
      "C: child in seen, child - b , return\n",
      "EXITING preorder_traversal !!!\n"
     ]
    }
   ],
   "source": [
    "# pickle_cycle.py\n",
    "import pickle\n",
    "\n",
    "\n",
    "class Node:\n",
    "    \"\"\"A simple digraph\n",
    "    \"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.connections = []\n",
    "\n",
    "    def add_edge(self, node):\n",
    "        \"Create an edge between this node and the other.\"\n",
    "        self.connections.append(node)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.connections)\n",
    "\n",
    "\n",
    "def preorder_traversal(root, seen=None, parent=None):\n",
    "    \"\"\"Generator function to yield the edges in a graph.\n",
    "    \"\"\"\n",
    "    print('ENTERING preorder_traversal', end=' ')\n",
    "    if parent is not None:\n",
    "        print('\"parent:{}({})\"'.format(parent.name, id(parent)), end = ' ')\n",
    "    else:\n",
    "        print('\"parent:{}({})\"'.format(type(parent), id(parent)), end = ' ')\n",
    "    if root is not None:\n",
    "        print('\"child:{}({})\"'.format(root.name, id(root)), end = ' ')\n",
    "    else:\n",
    "        print('\"child:{}({})\"'.format(type(root), id(root)), end = ' ')\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    print('\\nA: seen ', list((x.name, id(x)) for x in seen))\n",
    "    if parent is not None:\n",
    "        print('B: yield: {}({}), {}({}) '.format(parent.name, id(parent), root.name, id(root)))\n",
    "    else:\n",
    "        print('B: yield: {}({}), {}({}) '.format(type(parent), id(parent), root.name, id(root)))\n",
    "    yield (parent, root)   \n",
    "    if root in seen:\n",
    "        print('C: child in seen, child - {} , return'.format(root.name))\n",
    "        return\n",
    "    seen.add(root)\n",
    "    print('D: seen after seen.add(child) ', list((x.name, id(x)) for x in seen))\n",
    "    for node in root:\n",
    "        print('E: Iter {}({}) and got subnode {}({})'.format( root.name,id(root), node.name,id(node)))\n",
    "        recurse = preorder_traversal(node, seen, root)\n",
    "        for parent, subnode in recurse:\n",
    "            print('F: yield: {}({}), {}({}) '.format(parent.name, id(parent), subnode.name, id(subnode)))\n",
    "            yield (parent, subnode)\n",
    "    print('EXITING preorder_traversal !!!')\n",
    "\n",
    "\n",
    "def show_edges(root):\n",
    "    \"Print all the edges in the graph.\"\n",
    "    for parent, child in preorder_traversal(root):       \n",
    "        if not parent:\n",
    "            print('[SHOW_EDGE] parent - {}, continue'.format(type(parent)))\n",
    "            continue\n",
    "        print('     ******[SHOW_EDGE]****** {:>5} ({}) -> {:>2} ({})'.format(\n",
    "            parent.name, id(parent), child.name, id(child)))\n",
    "\n",
    "\n",
    "# Set up the nodes.\n",
    "root = Node('root')\n",
    "a = Node('a')\n",
    "b = Node('b')\n",
    "c = Node('c')\n",
    "\n",
    "# Add edges between them.\n",
    "root.add_edge(a)\n",
    "root.add_edge(b)\n",
    "a.add_edge(b)\n",
    "# b.add_edge(a)\n",
    "# b.add_edge(c)\n",
    "# a.add_edge(a)\n",
    "\n",
    "print('ORIGINAL GRAPH:')\n",
    "show_edges(root)\n",
    "\n",
    "# # Pickle and unpickle the graph to create\n",
    "# # a new set of nodes.\n",
    "# dumped = pickle.dumps(root)\n",
    "# reloaded = pickle.loads(dumped)\n",
    "\n",
    "# print('\\nRELOADED GRAPH:')\n",
    "# show_edges(reloaded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
