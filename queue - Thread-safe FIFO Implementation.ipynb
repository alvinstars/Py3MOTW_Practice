{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# queue — Thread-safe FIFO Implementation¶\n",
    "\n",
    "Purpose:\tProvides a thread-safe FIFO implementation\n",
    "\n",
    "The queue module provides a first-in, first-out (FIFO) data structure suitable for multi-threaded programming. It can be used to pass messages or other data between producer and consumer threads safely. Locking is handled for the caller, so many threads can work with the same Queue instance safely and easily. The size of a Queue (the number of elements it contains) may be restricted to throttle memory usage or processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic FIFO Queue\n",
    "\n",
    "The Queue class implements a basic first-in, first-out container. Elements are added to one “end” of the sequence using put(), and removed from the other end using get()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 \n"
     ]
    }
   ],
   "source": [
    "# queue_fifo.py\n",
    "\n",
    "import queue\n",
    "\n",
    "q = queue.Queue()\n",
    "\n",
    "for i in range(10):\n",
    "    q.put(i)\n",
    "\n",
    "while not q.empty():\n",
    "    print(q.get(), end=' ')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIFO Queue\n",
    "\n",
    "In contrast to the standard FIFO implementation of Queue, the LifoQueue uses last-in, first-out ordering (normally associated with a stack data structure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 8 7 6 5 4 3 2 1 0 \n"
     ]
    }
   ],
   "source": [
    "# queue_info.py\n",
    "\n",
    "import queue\n",
    "\n",
    "q = queue.LifoQueue()\n",
    "\n",
    "for i in range(10):\n",
    "    q.put(i)\n",
    "\n",
    "while not q.empty():\n",
    "    print(q.get(), end=' ')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priority Queue\n",
    "\n",
    "Sometimes the processing order of the items in a queue needs to be based on characteristics of those items, rather than just the order they are created or added to the queue. \n",
    "\n",
    "For example, print jobs from the payroll department may take precedence over a code listing printed by a developer. \n",
    "\n",
    "PriorityQueue uses the sort order of the contents of the queue to decide which to retrieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating New job: (3) Mid-level job\n",
      "Creating New job: (10) Low-level job\n",
      "Creating New job: (1) Important job\n",
      "Processing job: (1) Important job\n",
      "Processing job: (3) Mid-level job\n",
      "Processing job: (10) Low-level job\n"
     ]
    }
   ],
   "source": [
    "#queue_priority.py\n",
    "\n",
    "import functools\n",
    "import queue\n",
    "import threading\n",
    "\n",
    "\n",
    "@functools.total_ordering\n",
    "class Job:\n",
    "\n",
    "    def __init__(self, priority, description):\n",
    "        self.priority = priority\n",
    "        self.description = description\n",
    "        print('Creating New job: ({}) {}'.format(priority , description))\n",
    "        return\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        try:\n",
    "            return self.priority == other.priority\n",
    "        except AttributeError:\n",
    "            return NotImplemented\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        try:\n",
    "            return self.priority < other.priority\n",
    "        except AttributeError:\n",
    "            return NotImplemented\n",
    "\n",
    "\n",
    "q = queue.PriorityQueue()\n",
    "\n",
    "q.put(Job(3, 'Mid-level job'))\n",
    "q.put(Job(10, 'Low-level job'))\n",
    "q.put(Job(1, 'Important job'))\n",
    "\n",
    "\n",
    "def process_job(q):\n",
    "    while True:\n",
    "        next_job = q.get()\n",
    "        print('Processing job: ({})'.format(next_job.priority), next_job.description)\n",
    "        q.task_done()\n",
    "\n",
    "workers = [\n",
    "    threading.Thread(target=process_job, args=(q,)),\n",
    "    threading.Thread(target=process_job, args=(q,)),\n",
    "]\n",
    "for w in workers:\n",
    "    w.setDaemon(True)\n",
    "    w.start()\n",
    "\n",
    "q.join()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This example has multiple threads consuming the jobs, which are be processed based on the priority of items in the queue at the time get() was called. The order of processing for items added to the queue while the consumer threads are running depends on thread context switching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Threaded Podcast Client\n",
    "\n",
    "The source code for the podcasting client in this section demonstrates how to use the Queue class with multiple threads. The program reads one or more RSS feeds, queues up the enclosures for the five most recent episodes from each feed to be downloaded, and processes several downloads in parallel using threads. It does not have enough error handling for production use, but the skeleton implementation provides an example of using the queue module."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "First, some operating parameters are established. Normally these would come from user inputs (preferences, a database, etc.). The example uses hard-coded values for the number of threads and list of URLs to fetch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fetch_podcasts.py\n",
    "from queue import Queue\n",
    "import threading\n",
    "import time\n",
    "import urllib\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import os\n",
    "\n",
    "import feedparser\n",
    "\n",
    "# Set up some global variables\n",
    "num_fetch_threads = 2\n",
    "enclosure_queue = Queue()\n",
    "\n",
    "# A real app wouldn't use hard-coded data...\n",
    "feed_urls = [\n",
    "    'http://talkpython.fm/episodes/rss',\n",
    "]\n",
    "\n",
    "\n",
    "def message(s):\n",
    "    print('\\n{}: {}'.format(threading.current_thread().name, s))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The function download_enclosures() will run in the worker thread and process the downloads using urllib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def download_enclosures(q):\n",
    "    \"\"\"This is the worker thread function.\n",
    "    It processes items in the queue one after\n",
    "    another.  These daemon threads go into an\n",
    "    infinite loop, and only exit when\n",
    "    the main thread ends.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        message('looking for the next enclosure')\n",
    "        url = q.get()\n",
    "        filebase = './test' #create a test dir in current path\n",
    "        filename = url.rpartition('/')[-1]\n",
    "        filename_store = os.path.join(filebase,filename)\n",
    "        message('filename_store: {}'.format(filename_store))\n",
    "        message('downloading {}'.format(filename))\n",
    "        response = urllib.request.urlopen(url)\n",
    "        data = response.read()\n",
    "        # Save the downloaded file to the current directory\n",
    "        message('writing to {}'.format(filename_store))\n",
    "        with open(filename_store, 'wb') as outfile:\n",
    "            outfile.write(data)\n",
    "        q.task_done()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Once the target function for the threads is defined, the worker threads can be started. \n",
    "When download_enclosures() processes the statement url = q.get(), it blocks and waits until the queue has something to return. That means it is safe to start the threads before there is anything in the queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "worker-0: looking for the next enclosure\n",
      "\n",
      "worker-1: looking for the next enclosure\n"
     ]
    }
   ],
   "source": [
    "# Set up some threads to fetch the enclosures\n",
    "for i in range(num_fetch_threads):\n",
    "    worker = threading.Thread(\n",
    "        target=download_enclosures,\n",
    "        args=(enclosure_queue,),\n",
    "        name='worker-{}'.format(i),\n",
    "    )\n",
    "    worker.setDaemon(True)\n",
    "    worker.start()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The next step is to retrieve the feed contents using the feedparser module and enqueue the URLs of the enclosures. \n",
    "As soon as the first URL is added to the queue, one of the worker threads picks it up and starts downloading it. The loop will continue to add items until the feed is exhausted, and the worker threads will take turns dequeuing URLs to download them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MainThread: queuing grumpy-running-python-on-go.mp3\n",
      "\n",
      "MainThread: queuing guarenteed-packages-via-conda-and-conda-forge.mp3\n",
      "worker-1: filename_store: ./test/grumpy-running-python-on-go.mp3\n",
      "worker-0: filename_store: ./test/guarenteed-packages-via-conda-and-conda-forge.mp3\n",
      "\n",
      "\n",
      "\n",
      "MainThread: queuing spreading-python-through-the-sciences-with-software-carpentry.mp3\n",
      "worker-1: downloading grumpy-running-python-on-go.mp3\n",
      "worker-0: downloading guarenteed-packages-via-conda-and-conda-forge.mp3\n",
      "\n",
      "\n",
      "\n",
      "MainThread: queuing bonus-python-bytes-crossover-python-3.6-is-going-to-be-awesome-kite-your-friendly-co-developing-ai.mp3\n",
      "\n",
      "MainThread: queuing top-10-data-science-stories-of-2016.mp3\n",
      "\n",
      "worker-0: writing to ./test/guarenteed-packages-via-conda-and-conda-forge.mp3\n",
      "\n",
      "worker-0: looking for the next enclosure\n",
      "\n",
      "worker-0: filename_store: ./test/spreading-python-through-the-sciences-with-software-carpentry.mp3\n",
      "\n",
      "worker-0: downloading spreading-python-through-the-sciences-with-software-carpentry.mp3\n",
      "\n",
      "worker-1: writing to ./test/grumpy-running-python-on-go.mp3\n",
      "\n",
      "worker-1: looking for the next enclosure\n",
      "\n",
      "worker-1: filename_store: ./test/bonus-python-bytes-crossover-python-3.6-is-going-to-be-awesome-kite-your-friendly-co-developing-ai.mp3\n",
      "\n",
      "worker-1: downloading bonus-python-bytes-crossover-python-3.6-is-going-to-be-awesome-kite-your-friendly-co-developing-ai.mp3\n",
      "\n",
      "worker-1: writing to ./test/bonus-python-bytes-crossover-python-3.6-is-going-to-be-awesome-kite-your-friendly-co-developing-ai.mp3\n",
      "\n",
      "worker-1: looking for the next enclosure\n",
      "\n",
      "worker-1: filename_store: ./test/top-10-data-science-stories-of-2016.mp3\n",
      "\n",
      "worker-1: downloading top-10-data-science-stories-of-2016.mp3\n",
      "\n",
      "worker-0: writing to ./test/spreading-python-through-the-sciences-with-software-carpentry.mp3\n",
      "\n",
      "worker-0: looking for the next enclosure\n",
      "\n",
      "worker-1: writing to ./test/top-10-data-science-stories-of-2016.mp3\n",
      "\n",
      "worker-1: looking for the next enclosure\n"
     ]
    }
   ],
   "source": [
    "# Download the feed(s) and put the enclosure URLs into\n",
    "# the queue.\n",
    "for url in feed_urls:\n",
    "    response = feedparser.parse(url, agent='fetch_podcasts.py')\n",
    "    for entry in response['entries'][:5]:\n",
    "        for enclosure in entry.get('enclosures', []):\n",
    "            parsed_url = urlparse(enclosure['url'])\n",
    "            message('queuing {}'.format(\n",
    "                parsed_url.path.rpartition('/')[-1]))\n",
    "            enclosure_queue.put(enclosure['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MainThread: *** main thread waiting\n",
      "\n",
      "MainThread: *** done\n"
     ]
    }
   ],
   "source": [
    "# The only thing left to do is wait for the queue to empty out again, using join().\n",
    "\n",
    "# Now wait for the queue to be empty, indicating that we have\n",
    "# processed all of the downloads.\n",
    "message('*** main thread waiting')\n",
    "enclosure_queue.join()\n",
    "message('*** done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
